{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import make_data\n",
    "import datetime\n",
    "import requests\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import gensim as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 456, 419, 420, 421, 422, 838, 839, 840, 841, 842, 843, 884, 423, 424, 425, 426, 427, 1497, 428, 429, 430, 997, 1028, 1029, 1030, 1031, 1046, 1144, 1121, 1127, 1261, 1262, 1334, 1430]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7238\n"
     ]
    }
   ],
   "source": [
    "sm = 0\n",
    "for i in names:\n",
    "    f = open('data/categories/{}_urls.txt'.format(i))\n",
    "    lines = f.readlines()\n",
    "    sm += len(lines)\n",
    "    f.close()\n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = np.load('data/tree.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dfs(tree, parents, childrens):\n",
    "    mas = []\n",
    "    if tree['children'] != None:\n",
    "        for i in tree['children']:\n",
    "            parents[i['a_attr']['title'].split('.')[0]] = tree['a_attr']['title'].split('.')[0]\n",
    "            mas.extend([i['a_attr']['title'].split('.')[0]])\n",
    "            dfs(i, parents, childrens)\n",
    "    childrens[tree['a_attr']['title'].split('.')[0]] = mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parents = {'0':'0'}\n",
    "childrens = {}\n",
    "for i in tree:\n",
    "    parents[i['a_attr']['title'].split('.')[0]] = '0'\n",
    "    dfs(i, parents, childrens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(tree, names, allUrls, parent_numb, st):\n",
    "    dataUrls = []\n",
    "    dataText = []\n",
    "    dataCategories = []\n",
    "    \n",
    "    number = int(tree['a_attr']['title'].split('.')[0])\n",
    "    if number in names and number in files:\n",
    "        f = open('data/filterData/categories/{}.txt'.format(number))\n",
    "        lines = f.readlines()\n",
    "        categUrls = [i.split(', ', 1)[0] for i in lines]\n",
    "        categText = [i.split(', ', 1)[1] for i in lines]\n",
    "        f.close()\n",
    "        \n",
    "        for i in range(len(categUrls)):\n",
    "            if categUrls[i] not in allUrls:\n",
    "                dataUrls.extend([categUrls[i]])\n",
    "                dataText.append([categText[i].replace('\\n', '')])\n",
    "                dataCategories.extend([number])\n",
    "\n",
    "                allUrls.add(categUrls[i])\n",
    "            \n",
    "    if len(tree['children']) != 0:\n",
    "        for i in tree['children']:\n",
    "            a, b, c = getData(i, names, allUrls, number, st)\n",
    "            dataUrls.extend(a)\n",
    "            dataText.extend(b)\n",
    "            dataCategories.extend(c)\n",
    "    \n",
    "    else:\n",
    "        if number in names and number in files \\\n",
    "            and (len(categUrls) - len(dataUrls)) / len(categUrls) > 0.8:\n",
    "            dataCategories = (np.ones(len(dataCategories)) * parent_numb).tolist()\n",
    "\n",
    "    return dataUrls, dataText, dataCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('data/filterData/categories/*')\n",
    "files = [int(i[27:].split('.')[0]) for i in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allUrls = set()\n",
    "dataUrls = []\n",
    "dataText = []\n",
    "dataCategories = []\n",
    "st = '   '\n",
    "parent_numb = 1\n",
    "for i in tree:\n",
    "    a, b, c = getData(i, names, allUrls, parent_numb, st)\n",
    "    dataUrls.extend(a)\n",
    "    dataText.extend(b)\n",
    "    dataCategories.extend(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataUrls = np.array(dataUrls)\n",
    "dataText = np.array(dataText,  dtype='O')\n",
    "dataCategories = np.array(dataCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataUrls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataAns = [(dataUrls[i], dataCategories[i]) for i in range(dataUrls.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import RidgeClassifier, LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainText = np.load('data/filterData/patTrainText.npy')\n",
    "trainAns = np.load('data/filterData/patTrainAns.npy')\n",
    "testText = np.load('data/filterData/patTestText.npy')\n",
    "testAns = np.load('data/filterData/patTestAns.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainCategory = [float(i[1]) for i in trainAns]\n",
    "testCategory = [float(i[1]) for i in testAns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainTexts = trainText\n",
    "testTexts = testText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainTokens = np.array([i.split() for i in trainTexts])\n",
    "testTokens = np.array([i.split() for i in testTexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.6 s, sys: 224 ms, total: 43.8 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_w2v = gs.models.Word2Vec(trainTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.array(model_w2v.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_vec = np.array([model_w2v[i] for i in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, n_jobs=1, n_init=1)#, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=4000, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(words_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_center = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_dist = np.copy(words_vec)\n",
    "for i in range(n_clusters):\n",
    "    words_dist[words_labels == i] -= cluster_center[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_dict = dict()\n",
    "for i, word in enumerate(words):\n",
    "    words_dict[word] = np.array([words_labels[i], words_dist[i]], dtype='O')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "trainFeatures = np.zeros((trainTokens.shape[0], 100))\n",
    "for i in range(trainTokens.shape[0]):\n",
    "    for j in trainTokens[i]:\n",
    "        if j in model_w2v:\n",
    "            trainFeatures[i] += words_dict[j][1]\n",
    "#     trainFeatures[i] /= len(trainTokens[i]) + 1\n",
    "    \n",
    "testFeatures = np.zeros((testTokens.shape[0], 100))\n",
    "for i in range(testTokens.shape[0]):\n",
    "    for j in testTokens[i]:\n",
    "        if j in model_w2v:\n",
    "            testFeatures[i] += words_dict[j][1]\n",
    "#     testFeatures[i] /= len(testTokens[i]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFeatures = np.zeros((trainTokens.shape[0]), dtype='O')\n",
    "for i in range(trainTokens.shape[0]):\n",
    "    trainFeatures[i] = ''\n",
    "    for j in trainTokens[i]:\n",
    "        if j in model_w2v:\n",
    "            trainFeatures[i] += str(words_dict[j][0]) + ' '\n",
    "    \n",
    "testFeatures = np.zeros((testTokens.shape[0]), dtype='O')\n",
    "for i in range(testTokens.shape[0]):\n",
    "    testFeatures[i] = ''\n",
    "    for j in testTokens[i]:\n",
    "        if j in model_w2v:\n",
    "            testFeatures[i] += str(words_dict[j][0]) + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfTransformer = TfidfVectorizer()\n",
    "trainFeatures  = tfidfTransformer.fit_transform(trainFeatures)\n",
    "testFeatures = tfidfTransformer.transform(testFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5003, 3990)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  13.767823934555054\n",
      "0.740207833733\n",
      "0.8129496402877698\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = RidgeClassifier()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  28.665388345718384\n",
    "0.737809752198\n",
    "0.8161470823341327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  6.138647079467773\n",
      "0.734612310152\n",
      "0.8041566746602717\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = LogisticRegression()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  5.883610963821411\n",
    "0.697841726619\n",
    "0.7833733013589129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  0.09091615676879883\n",
      "0.674660271783\n",
      "0.7921662669864109\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = NearestCentroid()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  0.13930439949035645\n",
    "0.637889688249\n",
    "0.7809752198241406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  0.009717941284179688\n",
      "0.565947242206\n",
      "0.6442845723421263\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  0.010518789291381836\n",
    "0.649880095923\n",
    "0.7338129496402878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  0.007257223129272461\n",
      "0.675459632294\n",
      "0.7721822541966427\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = KNeighborsClassifier(algorithm='brute', metric='cosine')\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  0.008653879165649414\n",
    "0.677857713829\n",
    "0.7569944044764189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  67.46084332466125\n",
      "0.116706634692\n",
      "0.1486810551558753\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = SVC()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  101.92325091362\n",
    "0.121502797762\n",
    "0.14788169464428458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  61.66218447685242\n",
      "0.72342126299\n",
      "0.8113509192645884\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = SVC(gamma=0.5)\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fit time:  138.58860111236572\n",
    "0.689848121503\n",
    "0.7913669064748201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
