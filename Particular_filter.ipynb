{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import make_data\n",
    "import datetime\n",
    "import requests\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import gensim as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 456, 419, 420, 421, 422, 838, 839, 840, 841, 842, 843, 884, 423, 424, 425, 426, 427, 1497, 428, 429, 430, 997, 1028, 1029, 1030, 1031, 1046, 1144, 1121, 1127, 1261, 1262, 1334, 1430]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7238\n"
     ]
    }
   ],
   "source": [
    "sm = 0\n",
    "for i in names:\n",
    "    f = open('data/categories/{}_urls.txt'.format(i))\n",
    "    lines = f.readlines()\n",
    "    sm += len(lines)\n",
    "    f.close()\n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "headers0 = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:48.0) Gecko/20100101 Firefox/48.0',\n",
    "    'accept': \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    'accept-language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',\n",
    "    'keep-alive': 'keep-alive',\n",
    "    'cache-control': 'max-age=0',\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "URL = 'http://admining.hadoop1.corp.mail.ru/login/'\n",
    "logn = 'a.tleubayev'\n",
    "passwd = ''\n",
    "client = requests.session()\n",
    "\n",
    "client.get(URL)\n",
    "csrftoken = client.cookies['csrftoken']\n",
    "\n",
    "login_data = dict(username=logn, password=passwd,\n",
    "                  csrfmiddlewaretoken=csrftoken, next='/')\n",
    "r = client.post(URL, data=login_data, headers=dict(Referer=URL))\n",
    "\n",
    "if len(r.content) < 5000:\n",
    "    print('Неверно введен логин или пароль')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "url = 'http://admining.hadoop1.corp.mail.ru/api/load_tree/'\n",
    "try:\n",
    "    page = requests.get(url, timeout=10)\n",
    "except requests.exceptions.Timeout:\n",
    "    print('Ошибка подключения к admining.hadoop1.corp.mail.ru, проверьте подключение к VPN.')\n",
    "    exit(1)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "tree = json.loads(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = np.load('data/tree.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dfs(tree, parents, childrens):\n",
    "    mas = []\n",
    "    if tree['children'] != None:\n",
    "        for i in tree['children']:\n",
    "            parents[i['a_attr']['title'].split('.')[0]] = tree['a_attr']['title'].split('.')[0]\n",
    "            mas.extend([i['a_attr']['title'].split('.')[0]])\n",
    "            dfs(i, parents, childrens)\n",
    "    childrens[tree['a_attr']['title'].split('.')[0]] = mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parents = {'0':'0'}\n",
    "childrens = {}\n",
    "for i in tree:\n",
    "    parents[i['a_attr']['title'].split('.')[0]] = '0'\n",
    "    dfs(i, parents, childrens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(tree, names, allUrls, parent_numb, st):\n",
    "    dataUrls = []\n",
    "    dataText = []\n",
    "    dataCategories = []\n",
    "    \n",
    "    number = int(tree['a_attr']['title'].split('.')[0])\n",
    "    if number in names and number in files:\n",
    "        f = open('data/filterData/categories/{}.txt'.format(number))\n",
    "        lines = f.readlines()\n",
    "        categUrls = [i.split(', ', 1)[0] for i in lines]\n",
    "        categText = [i.split(', ', 1)[1] for i in lines]\n",
    "        f.close()\n",
    "        \n",
    "        for i in range(len(categUrls)):\n",
    "            if categUrls[i] not in allUrls:\n",
    "                dataUrls.extend([categUrls[i]])\n",
    "                dataText.append([categText[i].replace('\\n', '')])\n",
    "                dataCategories.extend([number])\n",
    "\n",
    "                allUrls.add(categUrls[i])\n",
    "            \n",
    "    if len(tree['children']) != 0:\n",
    "        for i in tree['children']:\n",
    "            a, b, c = getData(i, names, allUrls, number, st)\n",
    "            dataUrls.extend(a)\n",
    "            dataText.extend(b)\n",
    "            dataCategories.extend(c)\n",
    "    \n",
    "    else:\n",
    "        if number in names and number in files \\\n",
    "            and (len(categUrls) - len(dataUrls)) / len(categUrls) > 0.8:\n",
    "            dataCategories = (np.ones(len(dataCategories)) * parent_numb).tolist()\n",
    "\n",
    "    return dataUrls, dataText, dataCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('data/filterData/categories/*')\n",
    "files = [int(i[27:].split('.')[0]) for i in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allUrls = set()\n",
    "dataUrls = []\n",
    "dataText = []\n",
    "dataCategories = []\n",
    "st = '   '\n",
    "parent_numb = 1\n",
    "for i in tree:\n",
    "    a, b, c = getData(i, names, allUrls, parent_numb, st)\n",
    "    dataUrls.extend(a)\n",
    "    dataText.extend(b)\n",
    "    dataCategories.extend(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataUrls = np.array(dataUrls)\n",
    "dataText = np.array(dataText,  dtype='O')\n",
    "dataCategories = np.array(dataCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataUrls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataAns = [(dataUrls[i], dataCategories[i]) for i in range(dataUrls.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aaa = list(set(dataCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataUrls1 = np.array([])\n",
    "dataText1 = np.array([],  dtype='O')\n",
    "dataCategories1 = np.array([])\n",
    "for i in aaa:\n",
    "    if np.sum(dataCategories == i) > 1:\n",
    "        dataUrls1 = np.append(dataUrls1, dataUrls[dataCategories == i])\n",
    "        dataText1 = np.append(dataText1, dataText[dataCategories == i])\n",
    "        dataCategories1 = np.append(dataCategories1, dataCategories[dataCategories == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataUrls = dataUrls1\n",
    "dataText = dataText1\n",
    "dataCategories = dataCategories1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataAns = [(dataUrls[i], dataCategories[i]) for i in range(dataUrls.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainText, testText, trainAns, testAns = \\\n",
    "    train_test_split(dataText, dataAns, test_size=0.2, stratify=dataCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import RidgeClassifier, LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.save('data/filterData/patTrainText.npy', trainText)\n",
    "np.save('data/filterData/patTrainAns.npy', trainAns)\n",
    "np.save('data/filterData/patTestText.npy', testText)\n",
    "np.save('data/filterData/patTestAns.npy', testAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainText = np.load('data/filterData/patTrainText.npy')\n",
    "trainAns = np.load('data/filterData/patTrainAns.npy')\n",
    "testText = np.load('data/filterData/patTestText.npy')\n",
    "testAns = np.load('data/filterData/patTestAns.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainCategory = [float(i[1]) for i in trainAns]\n",
    "testCategory = [float(i[1]) for i in testAns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b26912db3566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainText\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "words = {}\n",
    "for i in trainText:\n",
    "    for j in i[0].split():\n",
    "        if j in words:\n",
    "            words[j] += 1\n",
    "        else:\n",
    "            words[j] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "mas = [[x,y] for x,y in list(words.items())]\n",
    "mas = np.array(mas, dtype='O')\n",
    "wordsSort = mas[mas[:,1].argsort()]\n",
    "oneWord = wordsSort[wordsSort[:,1] < 5][:,0]\n",
    "\n",
    "stopWord = {i:0 for i in oneWord}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "mas = [[x,y] for x,y in list(words.items())]\n",
    "mas = np.array(mas, dtype='O')\n",
    "wordsSort = mas[mas[:,1].argsort()]\n",
    "oneWord = wordsSort[wordsSort[:,1] < 5][:,0]\n",
    "\n",
    "stopWord = {i:0 for i in oneWord}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for idx, i in enumerate(trainText):\n",
    "    for j in i[0].split():\n",
    "        if j in stopWord:\n",
    "            stopWord[j] = idx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_time = time.time()\n",
    "for i in stopWord:\n",
    "    trainText[stopWord[i], 0] = trainText[stopWord[i], 0].replace(i, '')\n",
    "print(time.time() - _time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainTexts = trainText\n",
    "testTexts = testText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainTokens = np.array([i.split() for i in trainTexts])\n",
    "testTokens = np.array([i.split() for i in testTexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 s, sys: 116 ms, total: 43.3 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_w2v = gs.models.Word2Vec(trainTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mas = model_w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-fdbd26e9001d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainTokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_w2v\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mtrainFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel_w2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrainFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainTokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \"\"\"\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainFeatures = np.zeros((trainTokens.shape[0], 100))\n",
    "for i in range(trainTokens.shape[0]):\n",
    "    for j in trainTokens[i]:\n",
    "        if j in model_w2v:\n",
    "            trainFeatures[i] += model_w2v[j]\n",
    "    trainFeatures[i] /= len(trainTokens[i]) + 1\n",
    "    \n",
    "testFeatures = np.zeros((testTokens.shape[0], 100))\n",
    "for i in range(testTokens.shape[0]):\n",
    "    for j in testTokens[i]:\n",
    "        if j in model_w2v:\n",
    "            testFeatures[i] += model_w2v[j]\n",
    "    testFeatures[i] /= len(testTokens[i]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfTransformer = TfidfVectorizer()\n",
    "trainFeatures  = tfidfTransformer.fit_transform(trainTexts)\n",
    "testFeatures = tfidfTransformer.transform(testTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5003x81614 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1633026 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4381"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(trainFeatures != 0, axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326.40935438736756"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.sum(trainFeatures != 0, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  19.248169660568237\n",
      "0.716227018385\n",
      "0.7913669064748201\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = LogisticRegression()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  5.883610963821411\n",
    "0.697841726619\n",
    "0.7833733013589129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  23.949588775634766\n",
      "0.747402078337\n",
      "0.8185451638689049\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = RidgeClassifier()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  28.665388345718384\n",
    "0.737809752198\n",
    "0.8161470823341327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  0.14675235748291016\n",
      "0.669064748201\n",
      "0.812150279776179\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = NearestCentroid()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  0.13930439949035645\n",
    "0.637889688249\n",
    "0.7809752198241406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  0.010329723358154297\n",
      "0.676258992806\n",
      "0.7553956834532374\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  0.010518789291381836\n",
    "0.649880095923\n",
    "0.7338129496402878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  0.008327960968017578\n",
      "0.693844924061\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = KNeighborsClassifier(algorithm='brute', metric='cosine')\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  0.008653879165649414\n",
    "0.677857713829\n",
    "0.7569944044764189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  74.06704688072205\n",
      "0.116706634692\n",
      "0.1486810551558753\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = SVC()\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fit time:  101.92325091362\n",
    "0.121502797762\n",
    "0.14788169464428458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  100.61144852638245\n",
      "0.713029576339\n",
      "0.8033573141486811\n"
     ]
    }
   ],
   "source": [
    "_time = time.time()\n",
    "clf = SVC(gamma=0.5)\n",
    "clf.fit(trainFeatures, trainCategory)\n",
    "print('Fit time: ', time.time() - _time)\n",
    "predict = clf.predict(testFeatures)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategory, predict))\n",
    "for i in range(len(testCategory)):\n",
    "    if testCategory[i] == predict[i] or \\\n",
    "        parents[str(int(testCategory[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategory[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategory))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fit time:  138.58860111236572\n",
    "0.689848121503\n",
    "0.7913669064748201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
