{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import make_data\n",
    "import datetime\n",
    "import requests\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import gensim as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import RidgeClassifier, LinearRegression, LogisticRegression\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = np.load('data/tree.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dfs(tree, parents, childrens):\n",
    "    mas = []\n",
    "    if tree['children'] != None:\n",
    "        for i in tree['children']:\n",
    "            parents[i['a_attr']['title'].split('.')[0]] = tree['a_attr']['title'].split('.')[0]\n",
    "            mas.extend([i['a_attr']['title'].split('.')[0]])\n",
    "            dfs(i, parents, childrens)\n",
    "    childrens[tree['a_attr']['title'].split('.')[0]] = mas\n",
    "\n",
    "parents = {'0':'0'}\n",
    "childrens = {}\n",
    "for i in tree:\n",
    "    parents[i['a_attr']['title'].split('.')[0]] = '0'\n",
    "    dfs(i, parents, childrens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = {}\n",
    "names[91] = [91, 111, 106, 104, 101, 327, 331, 332, 335, 94, 346, 348, 352, 401, 798, 92, 245, 325, 97, 1198, 1124, 1126, 1205, 1206, 1183, 1204]\n",
    "names[1186] = [1186, 1187, 1188]\n",
    "names[1190] = [1190, 1191]\n",
    "names[90] = [90, 147, 159, 161, 1080, 157, 1081, 1100, 1101, 1102, 1103, 150, 173, 174, 175, 443, 1099, 154, 176, 177, 178, 179, 180, 156, 158, 162, 163, 1104, 1237, 164, 165, 166, 167, 916, 919, 168, 169, 170, 171, 172, 917, 918, 1105]\n",
    "names[89] = [89, 141, 142, 143, 139, 136, 137, 138, 133, 135, 134, 131, 126, 130, 129, 127, 128, 123, 125, 124, 116, 122, 119, 121, 120, 117, 118, 936, 105, 114, 115, 113, 112, 110, 108, 107, 937, 103, 93, 98, 102, 99, 100, 96, 95, 132, 144, 145, 146, 148, 149, 151, 152, 153]\n",
    "names[457] = [457, 458, 637, 638, 459, 460, 461, 639, 640, 462, 464, 641, 466, 595, 596, 597, 636]\n",
    "names[181] = [181, 182, 193, 200, 446, 197, 218, 219, 220, 221, 222, 223, 224, 225, 198, 201, 235, 202, 240, 243, 448, 449, 451, 452, 203, 204, 445, 970, 226, 228, 229, 230, 231, 227, 199]\n",
    "names[249] = [249, 250, 263, 274, 276, 277, 1388, 1422, 292, 1389, 303, 306, 307, 308, 1384, 1385, 1386, 1387, 310, 312, 314, 316, 1424, 1145]\n",
    "names[405] = [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 456, 419, 420, 421, 422, 838, 839, 840, 841, 842, 843, 884, 423, 424, 425, 426, 427, 1497, 428, 429, 430, 997, 1028, 1029, 1030, 1031, 1046, 1144, 1121, 1127, 1261, 1262, 1334, 1430]\n",
    "names[431] = [431, 1189, 432, 433, 435, 436, 437, 439, 442, 453, 454, 1079]\n",
    "names[705] = [705, 194, 196, 210, 1499, 1500, 1501, 706, 707, 708, 709, 711, 725, 712, 713, 714, 715, 716, 717, 767, 768, 1143, 1214, 1345, 720, 721, 722, 1213, 723]\n",
    "names[474] = [474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507]\n",
    "names[560] = [560, 563, 564, 566, 570, 589, 1074, 576, 585, 578, 586, 579, 587, 583, 590, 591, 592, 1082]\n",
    "names[598] = [598, 508, 509, 535, 510, 538, 1463, 539, 540, 547, 553, 554, 557, 573, 581, 1390, 892, 1219, 1377, 1234, 601, 600, 603, 1464, 1465, 604, 1220, 1397, 1221, 1223, 613, 629, 1240, 1241, 1242, 1243, 1244, 1250, 1289, 614, 615, 616, 617, 618, 620, 621, 1327, 630, 1245, 1323, 1328, 631, 1320, 1321, 1322, 634, 1247, 1248, 1249, 1083, 619, 1292, 1294, 1084, 1326, 1286, 1288, 1290, 622, 623, 624, 625, 626, 627, 628, 635, 1291, 1295, 1299, 1316, 1317, 632, 1246, 1252, 1253, 1254, 1255, 633, 1296, 1297, 1298, 1318, 1319, 1324, 1325, 1287, 1293, 1236, 1376, 1461, 1462]\n",
    "names[642] = [642, 643, 648, 649, 1182, 650, 959, 651, 652, 1157, 653, 654, 759, 644, 655, 1158, 656, 657, 658, 645, 659, 660, 1227, 647, 664, 1235, 1348, 1378, 1353, 1356, 1355, 1360, 1362, 1365, 1366, 1367, 1368, 1382, 1383, 1369, 1370, 1371, 1372, 661, 646, 662, 663, 799, 1132, 1133]\n",
    "names[668] = [668, 669, 674, 1229, 672, 673, 676, 677, 695, 697, 698, 699, 700, 670, 678, 679, 680, 683, 701, 702, 703, 704, 681, 1215, 1216, 1217, 1315]\n",
    "names[728] = [728, 729, 730, 732, 733, 769, 770, 771, 772, 773, 774, 775, 776, 1222, 734, 738, 739, 762, 743, 745, 747, 748, 764, 744, 749, 754, 755, 757, 750, 752, 753]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names[598])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(tree, names, allUrls, parent_numb, st):\n",
    "    dataUrls = []\n",
    "    dataText = []\n",
    "    dataCategories = []\n",
    "    \n",
    "    number = int(tree['a_attr']['title'].split('.')[0])\n",
    "    if number in names and number in files:\n",
    "        f = open('data/filterData/categories/{}.txt'.format(number))\n",
    "        lines = f.readlines()\n",
    "        categUrls = [i.split(', ', 1)[0] for i in lines]\n",
    "        categText = [i.split(', ', 1)[1] for i in lines]\n",
    "        f.close()\n",
    "        \n",
    "        for i in range(len(categUrls)):\n",
    "            if categUrls[i] not in allUrls:\n",
    "                dataUrls.extend([categUrls[i]])\n",
    "                dataText.append([categText[i].replace('\\n', '')])\n",
    "                dataCategories.extend([number])\n",
    "\n",
    "                allUrls.add(categUrls[i])\n",
    "            \n",
    "    if len(tree['children']) != 0:\n",
    "        for i in tree['children']:\n",
    "            a, b, c = getData(i, names, allUrls, number, st)\n",
    "            dataUrls.extend(a)\n",
    "            dataText.extend(b)\n",
    "            dataCategories.extend(c)\n",
    "    \n",
    "    else:\n",
    "        if number in names and number in files \\\n",
    "            and (len(categUrls) - len(dataUrls)) / len(categUrls) > 0.8:\n",
    "            dataCategories = (np.ones(len(dataCategories)) * parent_numb).tolist()\n",
    "\n",
    "    return dataUrls, dataText, dataCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('data/filterData/categories/*')\n",
    "files = [int(i[27:].split('.')[0]) for i in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allParents = {}\n",
    "for j in names:\n",
    "    allUrls = set()\n",
    "    dataUrls = []\n",
    "    dataText = []\n",
    "    dataCategories = []\n",
    "    st = '    '\n",
    "    parent_numb = 1\n",
    "    for i in tree:\n",
    "        a, b, c = getData(i, names[j], allUrls, parent_numb, st)\n",
    "        dataUrls.extend(a)\n",
    "        dataText.extend(b)\n",
    "        dataCategories.extend(c)\n",
    "    \n",
    "#     dataUrls = np.array(dataUrls)\n",
    "#     dataText = np.array(dataText,  dtype='O')\n",
    "#     dataCategories = np.array(dataCategories)\n",
    "\n",
    "    allParents[j] = (dataUrls, dataText, dataCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testAns = np.load('data/filterData/TestAns.npy')\n",
    "testUrl = [i[0] for i in testAns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testText = []\n",
    "testCategories = []\n",
    "for i in testUrl:\n",
    "    txt = ''\n",
    "    cat = 0\n",
    "    for j in allParents:\n",
    "        if i in allParents[j][0]:\n",
    "            idx = allParents[j][0].index(i)\n",
    "            txt = allParents[j][1][idx]\n",
    "            cat = allParents[j][2][idx]\n",
    "            \n",
    "            del allParents[j][0][idx]\n",
    "            del allParents[j][1][idx]\n",
    "            del allParents[j][2][idx]\n",
    "    \n",
    "    testText.extend([txt])\n",
    "    testCategories.extend([cat])\n",
    "testText = np.array(testText, dtype='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = {}\n",
    "# _time = time.time()\n",
    "# for k in allParents:\n",
    "#     texts = allParents[k][1]\n",
    "    \n",
    "#     texts = [i[0] for i in texts]\n",
    "    \n",
    "#     tfidfTransformer = TfidfVectorizer()\n",
    "#     tfidf = tfidfTransformer.fit_transform(texts)\n",
    "    \n",
    "#     features[k] = (tfidf, tfidfTransformer, allParents[k][2])\n",
    "\n",
    "# print(time.time() - _time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_clusters = 2000\n",
    "# features = {}\n",
    "# _time = time.time()\n",
    "# for k in allParents:\n",
    "#     _time2 = time.time()\n",
    "#     texts = allParents[k][1]\n",
    "    \n",
    "#     textsTokens = np.array([i[0].split() for i in texts])\n",
    "    \n",
    "#     model_w2v = gs.models.Word2Vec(textsTokens)\n",
    "#     words = np.array(model_w2v.wv.index2word)\n",
    "#     words_vec = np.array([model_w2v[i] for i in words])\n",
    "    \n",
    "#     kmeans = KMeans(n_clusters=n_clusters, n_jobs=1, n_init=1)#, random_state=0)\n",
    "#     kmeans.fit(words_vec)\n",
    "#     words_labels = kmeans.labels_\n",
    "    \n",
    "#     words_dict = dict()\n",
    "#     for i, word in enumerate(words):\n",
    "#         words_dict[word] = np.array([words_labels[i]], dtype='O')\n",
    "    \n",
    "#     trainFeatures = np.zeros((textsTokens.shape[0]), dtype='O')\n",
    "#     for i in range(textsTokens.shape[0]):\n",
    "#         trainFeatures[i] = ''\n",
    "#         for j in textsTokens[i]:\n",
    "#             if j in model_w2v:\n",
    "#                 trainFeatures[i] += str(words_dict[j][0]) + ' '\n",
    "    \n",
    "#     tfidfTransformer = TfidfVectorizer()\n",
    "#     trainFeatures  = tfidfTransformer.fit_transform(trainFeatures)\n",
    "#     testFeatures = tfidfTransformer.transform(testFeatures)\n",
    "\n",
    "#     features[k] = (trainFeatures, words_dict, tfidfTransformer, allParents[k][2])\n",
    "#     print(k, time.time() - _time2)\n",
    "# print(time.time() - _time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_clusters = 2000\n",
    "# features = {}\n",
    "# _time = time.time()\n",
    "# k = 598\n",
    "# # for k in allParents:\n",
    "# _time2 = time.time()\n",
    "# texts = allParents[k][1]\n",
    "\n",
    "# textsTokens = np.array([i[0].split() for i in texts])\n",
    "\n",
    "# model_w2v = gs.models.Word2Vec(textsTokens)\n",
    "# words = np.array(model_w2v.wv.index2word)\n",
    "# words_vec = np.array([model_w2v[i] for i in words])\n",
    "\n",
    "# kmeans = KMeans(n_clusters=n_clusters, n_jobs=1, n_init=1)#, random_state=0)\n",
    "# kmeans.fit(words_vec)\n",
    "# words_labels = kmeans.labels_\n",
    "\n",
    "# words_dict = dict()\n",
    "# for i, word in enumerate(words):\n",
    "#     words_dict[word] = np.array([words_labels[i]], dtype='O')\n",
    "\n",
    "# trainFeatures = np.zeros((textsTokens.shape[0]), dtype='O')\n",
    "# for i in range(textsTokens.shape[0]):\n",
    "#     trainFeatures[i] = ''\n",
    "#     for j in textsTokens[i]:\n",
    "#         if j in model_w2v:\n",
    "#             trainFeatures[i] += str(words_dict[j][0]) + ' '\n",
    "\n",
    "# tfidfTransformer = TfidfVectorizer()\n",
    "# trainFeatures  = tfidfTransformer.fit_transform(trainFeatures)\n",
    "\n",
    "# features[k] = (trainFeatures, words_dict, tfidfTransformer, allParents[k][2])\n",
    "# print(k, time.time() - _time2)\n",
    "# print(time.time() - _time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_clusters = 2000\n",
    "# features = {}\n",
    "# _time = time.time()\n",
    "# k = 598\n",
    "# # for k in allParents:\n",
    "# _time2 = time.time()\n",
    "# texts = allParents[k][1]\n",
    "\n",
    "# textsTokens = np.array([i[0].split() for i in texts])\n",
    "\n",
    "# model_w2v = gs.models.Word2Vec(textsTokens)\n",
    "# words = np.array(model_w2v.wv.index2word)\n",
    "# words_vec = np.array([model_w2v[i] for i in words])\n",
    "\n",
    "# kmeans = KMeans(n_clusters=n_clusters, n_jobs=1, n_init=1)#, random_state=0)\n",
    "# kmeans.fit(words_vec)\n",
    "# words_labels = kmeans.labels_\n",
    "\n",
    "# words_dict = dict()\n",
    "# for i, word in enumerate(words):\n",
    "#     words_dict[word] = np.array([words_labels[i]], dtype='O')\n",
    "\n",
    "# trainFeatures = np.zeros((textsTokens.shape[0]), dtype='O')\n",
    "# for i in range(textsTokens.shape[0]):\n",
    "#     trainFeatures[i] = ''\n",
    "#     for j in textsTokens[i]:\n",
    "#         if j in model_w2v:\n",
    "#             trainFeatures[i] += str(words_dict[j][0]) + ' '\n",
    "\n",
    "# tfidfTransformer = TfidfVectorizer()\n",
    "# trainFeatures  = tfidfTransformer.fit_transform(trainFeatures)\n",
    "\n",
    "# features[k] = (trainFeatures, words_dict, tfidfTransformer, allParents[k][2])\n",
    "# print(k, time.time() - _time2)\n",
    "# print(time.time() - _time)\n",
    "\n",
    "# key = 598\n",
    "# X, wdict, tfidfTransformer, y = features[key]\n",
    "\n",
    "# clfRC = RidgeClassifier()\n",
    "# clfRC.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masss = [1, 500, 1000, 2000, 3000, 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = np.zeros((len(names), len(masss), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ansStr = 'RC.npy'\n",
    "np.save('answer_table'+ansStr, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "1186\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "1190\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "90\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "89\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "457\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "181\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "249\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "405\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "431\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "705\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "474\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "560\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "598\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "642\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "668\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n",
      "728\n",
      "1\n",
      "500\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ik, key in enumerate(names.keys()):\n",
    "    print(key)\n",
    "    for inn, n_clusters in enumerate(masss):\n",
    "        texts = allParents[key][1]\n",
    "        if n_clusters == 1:\n",
    "            texts = [i[0] for i in texts]\n",
    "            tfidfTransformer = TfidfVectorizer()\n",
    "            tfidf = tfidfTransformer.fit_transform(texts)\n",
    "            X, tfidfTransformer, y = (tfidf, tfidfTransformer, allParents[key][2])\n",
    "        else:\n",
    "            textsTokens = np.array([i[0].split() for i in texts])\n",
    "\n",
    "            model_w2v = gs.models.Word2Vec(textsTokens)\n",
    "            words = np.array(model_w2v.wv.index2word)\n",
    "            words_vec = np.array([model_w2v[i] for i in words])\n",
    "\n",
    "            kmeans = KMeans(n_clusters=n_clusters, n_jobs=1, n_init=1)#, random_state=0)\n",
    "            kmeans.fit(words_vec)\n",
    "            words_labels = kmeans.labels_\n",
    "\n",
    "            words_dict = dict()\n",
    "            for i, word in enumerate(words):\n",
    "                words_dict[word] = np.array([words_labels[i]], dtype='O')\n",
    "\n",
    "            trainFeatures = np.zeros((textsTokens.shape[0]), dtype='O')\n",
    "            for i in range(textsTokens.shape[0]):\n",
    "                trainFeatures[i] = ''\n",
    "                for j in textsTokens[i]:\n",
    "                    if j in model_w2v:\n",
    "                        trainFeatures[i] += str(words_dict[j][0]) + ' '\n",
    "\n",
    "            tfidfTransformer = TfidfVectorizer()\n",
    "            trainFeatures  = tfidfTransformer.fit_transform(trainFeatures)\n",
    "\n",
    "            X, wdict, tfidfTransformer, y = (trainFeatures, words_dict, tfidfTransformer, allParents[key][2])\n",
    "\n",
    "        clfRC = RidgeClassifier()\n",
    "        clfRC.fit(X, y)\n",
    "\n",
    "        predict = np.load('data/filterData/multilevel/predict'+ansStr)\n",
    "        \n",
    "        idx = np.where(predict == key)[0]\n",
    "        if idx.shape[0] != 0:\n",
    "            testX = testText[idx]\n",
    "            testCategories1 = np.array(testCategories)[idx]\n",
    "            if n_clusters == 1:\n",
    "                testX = tfidfTransformer.transform([i[0] for i in testX])\n",
    "                predict = clfRC.predict(testX)\n",
    "            else:\n",
    "                testX = np.array([i[0].split() for i in testX])\n",
    "                testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "                for k in range(testX.shape[0]):\n",
    "                    testFeat[k] = ''\n",
    "                    for j in testX[k]:\n",
    "                        if j in wdict:\n",
    "                            testFeat[k] += str(wdict[j][0]) + ' '\n",
    "\n",
    "                testFeat = tfidfTransformer.transform(testFeat) \n",
    "                predict = clfRC.predict(testFeat)\n",
    "\n",
    "        sm = 0\n",
    "        print(n_clusters)\n",
    "        answer[ik, inn, 0] = round(accuracy_score(testCategories1, predict), 4)\n",
    "        for i in range(len(testCategories1)):\n",
    "            if testCategories1[i] == predict[i] or \\\n",
    "                parents[str(int(testCategories1[i]))] == str(int(predict[i])) or\\\n",
    "                str(int(predict[i])) in childrens[str(int(testCategories1[i]))]:\n",
    "                sm += 1\n",
    "        answer[ik, inn, 1] = round(sm / len(testCategories1), 4)\n",
    "        np.save('answer_table'+ansStr, answer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf 91\n",
      "0.673076923077\n",
      "0.7628205128205128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masss = [91]\n",
    "for kk in masss:\n",
    "    features = {}\n",
    "    _time = time.time()\n",
    "    k = kk\n",
    "    key = kk\n",
    "    # for k in allParents:\n",
    "    _time2 = time.time()\n",
    "    texts = allParents[k][1]\n",
    "    \n",
    "    texts = [i[0] for i in texts]\n",
    "    \n",
    "    tfidfTransformer = TfidfVectorizer()\n",
    "    tfidf = tfidfTransformer.fit_transform(texts)\n",
    "    \n",
    "    features[k] = (tfidf, tfidfTransformer, allParents[k][2])\n",
    "#     print(k, time.time() - _time2)\n",
    "#     print(time.time() - _time)\n",
    "\n",
    "    X, tfidfTransformer, y = features[key]\n",
    "\n",
    "    clfRC = RidgeClassifier()\n",
    "    clfRC.fit(X, y)\n",
    "    \n",
    "    predict = np.load('data/filterData/multilevel/predictLR.npy')\n",
    "    \n",
    "    idx = np.where(predict == key)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        testCategories1 = np.array(testCategories)[idx]\n",
    "        testX = tfidfTransformer.transform([i[0] for i in testX])\n",
    "\n",
    "        predict = clfRC.predict(testX)\n",
    "\n",
    "    sm = 0\n",
    "    print('tfidf', key)\n",
    "    print(accuracy_score(testCategories1, predict))\n",
    "    for i in range(len(testCategories1)):\n",
    "        if testCategories1[i] == predict[i] or \\\n",
    "            parents[str(int(testCategories1[i]))] == str(int(predict[i])) or\\\n",
    "            str(int(predict[i])) in childrens[str(int(testCategories1[i]))]:\n",
    "            sm += 1\n",
    "    print(sm / len(testCategories1))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "w2v 500\n",
      "0.634920634921\n",
      "0.7142857142857143\n",
      "\n",
      "w2v 1000\n",
      "0.608465608466\n",
      "0.708994708994709\n",
      "\n",
      "w2v 2000\n",
      "0.603174603175\n",
      "0.7037037037037037\n",
      "\n",
      "w2v 3000\n",
      "0.624338624339\n",
      "0.7195767195767195\n",
      "\n",
      "431\n",
      "w2v 500\n",
      "0.621917808219\n",
      "0.6794520547945205\n",
      "\n",
      "w2v 1000\n",
      "0.619178082192\n",
      "0.663013698630137\n",
      "\n",
      "w2v 2000\n",
      "0.624657534247\n",
      "0.673972602739726\n",
      "\n",
      "w2v 3000\n",
      "0.619178082192\n",
      "0.6767123287671233\n",
      "\n",
      "598\n",
      "w2v 500\n",
      "0.567286245353\n",
      "0.6438661710037175\n",
      "\n",
      "w2v 1000\n",
      "0.5843866171\n",
      "0.6654275092936803\n",
      "\n",
      "w2v 2000\n",
      "0.597026022305\n",
      "0.6788104089219331\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-8c1817e7cb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, random_state=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mwords_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialization complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     centers, labels, n_iter = k_means_elkan(X, n_clusters, centers, tol=tol,\n\u001b[0;32m--> 399\u001b[0;31m                                             max_iter=max_iter, verbose=verbose)\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0minertia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/cluster/_k_means_elkan.pyx\u001b[0m in \u001b[0;36msklearn.cluster._k_means_elkan.k_means_elkan (sklearn/cluster/_k_means_elkan.c:5295)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/adil/.pyenv/versions/3.6.1/envs/python3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m     \"\"\"\n\u001b[1;32m   1712\u001b[0m     \u001b[0mSum\u001b[0m \u001b[0mof\u001b[0m \u001b[0marray\u001b[0m \u001b[0melements\u001b[0m \u001b[0mover\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "massk = [91, 431, 598]\n",
    "masss = [500, 1000, 2000, 3000]\n",
    "for kk in massk:\n",
    "    print(kk)\n",
    "    for n_clusters in masss:\n",
    "        features = {}\n",
    "        _time = time.time()\n",
    "        k = kk\n",
    "        key = kk\n",
    "        # for k in allParents:\n",
    "        _time2 = time.time()\n",
    "        texts = allParents[k][1]\n",
    "\n",
    "        textsTokens = np.array([i[0].split() for i in texts])\n",
    "\n",
    "        model_w2v = gs.models.Word2Vec(textsTokens)\n",
    "        words = np.array(model_w2v.wv.index2word)\n",
    "        words_vec = np.array([model_w2v[i] for i in words])\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_jobs=1, n_init=1)#, random_state=0)\n",
    "        kmeans.fit(words_vec)\n",
    "        words_labels = kmeans.labels_\n",
    "\n",
    "        words_dict = dict()\n",
    "        for i, word in enumerate(words):\n",
    "            words_dict[word] = np.array([words_labels[i]], dtype='O')\n",
    "\n",
    "        trainFeatures = np.zeros((textsTokens.shape[0]), dtype='O')\n",
    "        for i in range(textsTokens.shape[0]):\n",
    "            trainFeatures[i] = ''\n",
    "            for j in textsTokens[i]:\n",
    "                if j in model_w2v:\n",
    "                    trainFeatures[i] += str(words_dict[j][0]) + ' '\n",
    "\n",
    "        tfidfTransformer = TfidfVectorizer()\n",
    "        trainFeatures  = tfidfTransformer.fit_transform(trainFeatures)\n",
    "\n",
    "        features[k] = (trainFeatures, words_dict, tfidfTransformer, allParents[k][2])\n",
    "    #     print(k, time.time() - _time2)\n",
    "    #     print(time.time() - _time)\n",
    "\n",
    "        X, wdict, tfidfTransformer, y = features[key]\n",
    "\n",
    "        clfRC = RidgeClassifier()\n",
    "        clfRC.fit(X, y)\n",
    "\n",
    "        predict = np.load('data/filterData/multilevel/predictRC.npy')\n",
    "\n",
    "        idx = np.where(predict == key)[0]\n",
    "        if idx.shape[0] != 0:\n",
    "            testX = testText[idx]\n",
    "            testCategories1 = np.array(testCategories)[idx]\n",
    "            wdict = features[key][1]\n",
    "            testX = np.array([i[0].split() for i in testX])\n",
    "            testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "            for k in range(testX.shape[0]):\n",
    "                testFeat[k] = ''\n",
    "                for j in testX[k]:\n",
    "                    if j in wdict:\n",
    "                        testFeat[k] += str(wdict[j][0]) + ' '\n",
    "\n",
    "            testFeat = features[key][2].transform(testFeat) \n",
    "            predict = clfRC.predict(testFeat)\n",
    "\n",
    "        sm = 0\n",
    "        print('w2v', n_clusters)\n",
    "        print(accuracy_score(testCategories1, predict))\n",
    "        for i in range(len(testCategories1)):\n",
    "            if testCategories1[i] == predict[i] or \\\n",
    "                parents[str(int(testCategories1[i]))] == str(int(predict[i])) or\\\n",
    "                str(int(predict[i])) in childrens[str(int(testCategories1[i]))]:\n",
    "                sm += 1\n",
    "        print(sm / len(testCategories1))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in features:\n",
    "    X, wdict, y = features[i]\n",
    "    \n",
    "    tfidfTransformer = TfidfVectorizer()\n",
    "    trainFeatures  = tfidfTransformer.fit_transform(X)\n",
    "    \n",
    "    features[i] = (trainFeatures, wdict, tfidfTransformer, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "Fit time:  1.9342756271362305\n",
      "Fit time:  3.528273820877075\n",
      "1186\n",
      "Fit time:  0.16826605796813965\n",
      "Fit time:  0.4192523956298828\n",
      "1190\n",
      "Fit time:  0.06460714340209961\n",
      "Fit time:  0.31431007385253906\n",
      "90\n",
      "Fit time:  18.80303645133972\n",
      "Fit time:  42.62992024421692\n",
      "89\n",
      "Fit time:  16.95978307723999\n",
      "Fit time:  17.42852807044983\n",
      "457\n",
      "Fit time:  5.974406003952026\n",
      "Fit time:  19.249268770217896\n",
      "181\n",
      "Fit time:  20.191059112548828\n",
      "Fit time:  45.128360748291016\n",
      "249\n",
      "Fit time:  2.820070505142212\n",
      "Fit time:  3.993708848953247\n",
      "405\n",
      "Fit time:  44.37754559516907\n",
      "Fit time:  96.20048260688782\n",
      "431\n",
      "Fit time:  3.8956515789031982\n",
      "Fit time:  8.320242404937744\n",
      "705\n",
      "Fit time:  23.725866556167603\n",
      "Fit time:  60.05344772338867\n",
      "474\n",
      "Fit time:  1.7348012924194336\n",
      "Fit time:  5.053372621536255\n",
      "560\n",
      "Fit time:  3.8908517360687256\n",
      "Fit time:  8.76661467552185\n",
      "598\n",
      "Fit time:  51.05008840560913\n",
      "Fit time:  131.50347447395325\n",
      "642\n",
      "Fit time:  11.809923648834229\n",
      "Fit time:  12.44684386253357\n",
      "668\n",
      "Fit time:  4.481785297393799\n",
      "Fit time:  11.025774717330933\n",
      "728\n",
      "Fit time:  12.748369455337524\n",
      "Fit time:  24.75827956199646\n",
      "All time:  716.8842306137085\n"
     ]
    }
   ],
   "source": [
    "clfRC = {}\n",
    "clfNC = {}\n",
    "clfKNN1 = {}\n",
    "clfKNN2 = {}\n",
    "clfSVC = {}\n",
    "clfLR = {}\n",
    "\n",
    "_time1 = time.time()\n",
    "for i in features:\n",
    "    print(i)\n",
    "    _time = time.time()\n",
    "#     X, wdict, tfidfTransformer, y = features[i]\n",
    "    X, tfidfTransformer, y = features[i]\n",
    "    \n",
    "    clfLR[i] = LogisticRegression()\n",
    "    clfLR[i].fit(X, y)\n",
    "    \n",
    "    clfRC[i] = RidgeClassifier()\n",
    "    clfRC[i].fit(X, y)\n",
    "    print('Fit time: ', time.time() - _time)\n",
    "\n",
    "    _time = time.time()\n",
    "    clfNC[i] = NearestCentroid()\n",
    "    clfNC[i].fit(X, y)\n",
    "#     print('Fit time: ', time.time() - _time)\n",
    "\n",
    "    _time = time.time()\n",
    "    clfKNN1[i] = KNeighborsClassifier()\n",
    "    clfKNN1[i].fit(X, y)\n",
    "#     print('Fit time: ', time.time() - _time)\n",
    "\n",
    "    _time = time.time()\n",
    "    clfKNN2[i] = KNeighborsClassifier(algorithm='brute', metric='cosine')\n",
    "    clfKNN2[i].fit(X, y)\n",
    "#     print('Fit time: ', time.time() - _time)\n",
    "\n",
    "    _time = time.time()\n",
    "    clfSVC[i] = SVC(gamma=0.5)\n",
    "    clfSVC[i].fit(X, y)\n",
    "    print('Fit time: ', time.time() - _time)\n",
    "print('All time: ', time.time() - _time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.586369531895\n",
      "0.6926070038910506\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictLR.npy')\n",
    "clf = clfLR\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        wdict = features[i][1]\n",
    "        testX = np.array([i[0].split() for i in testX])\n",
    "        testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "        for k in range(testX.shape[0]):\n",
    "            testFeat[k] = ''\n",
    "            for j in testX[k]:\n",
    "                if j in wdict:\n",
    "                    testFeat[k] += str(wdict[j][0]) + ' '\n",
    "        \n",
    "        testFeat = features[i][2].transform(testFeat) \n",
    "        predict[idx] = clf[i].predict(testFeat)\n",
    "        \n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.330621388987\n",
      "0.3775498172385332\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictKNN1.npy')\n",
    "clf = clfKNN1\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        wdict = features[i][1]\n",
    "        testX = np.array([i[0].split() for i in testX])\n",
    "        testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "        for k in range(testX.shape[0]):\n",
    "            testFeat[k] = ''\n",
    "            for j in testX[k]:\n",
    "                if j in wdict:\n",
    "                    testFeat[k] += str(wdict[j][0]) + ' '\n",
    "        \n",
    "        testFeat = features[i][2].transform(testFeat) \n",
    "        predict[idx] = clf[i].predict(testFeat)\n",
    "        \n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553000825374\n",
      "0.6562905317769131\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictKNN2.npy')\n",
    "clf = clfKNN2\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        wdict = features[i][1]\n",
    "        testX = np.array([i[0].split() for i in testX])\n",
    "        testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "        for k in range(testX.shape[0]):\n",
    "            testFeat[k] = ''\n",
    "            for j in testX[k]:\n",
    "                if j in wdict:\n",
    "                    testFeat[k] += str(wdict[j][0]) + ' '\n",
    "        \n",
    "        testFeat = features[i][2].transform(testFeat) \n",
    "        predict[idx] = clf[i].predict(testFeat)\n",
    "        \n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51196792831\n",
      "0.6283457139488268\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictNC.npy')\n",
    "clf = clfNC\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        wdict = features[i][1]\n",
    "        testX = np.array([i[0].split() for i in testX])\n",
    "        testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "        for k in range(testX.shape[0]):\n",
    "            testFeat[k] = ''\n",
    "            for j in testX[k]:\n",
    "                if j in wdict:\n",
    "                    testFeat[k] += str(wdict[j][0]) + ' '\n",
    "        \n",
    "        testFeat = features[i][2].transform(testFeat) \n",
    "        predict[idx] = clf[i].predict(testFeat)\n",
    "        \n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.615611366584\n",
      "0.7178398773729513\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictRC.npy')\n",
    "clf = clfRC\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        wdict = features[i][1]\n",
    "        testX = np.array([i[0].split() for i in testX])\n",
    "        testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "        for k in range(testX.shape[0]):\n",
    "            testFeat[k] = ''\n",
    "            for j in testX[k]:\n",
    "                if j in wdict:\n",
    "                    testFeat[k] += str(wdict[j][0]) + ' '\n",
    "        \n",
    "        testFeat = features[i][2].transform(testFeat) \n",
    "        predict[idx] = clf[i].predict(testFeat)\n",
    "        \n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584836693786\n",
      "0.6944935738710057\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictSVC1.npy')\n",
    "clf = clfSVC\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        wdict = features[i][1]\n",
    "        testX = np.array([i[0].split() for i in testX])\n",
    "        testFeat = np.zeros((testX.shape[0]), dtype='O')\n",
    "        for k in range(testX.shape[0]):\n",
    "            testFeat[k] = ''\n",
    "            for j in testX[k]:\n",
    "                if j in wdict:\n",
    "                    testFeat[k] += str(wdict[j][0]) + ' '\n",
    "        \n",
    "        testFeat = features[i][2].transform(testFeat) \n",
    "        predict[idx] = clf[i].predict(testFeat)\n",
    "        \n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.579059073222\n",
      "0.6860040089612074\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictLR.npy')\n",
    "clf = clfLR\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        testX = features[i][1].transform([i[0] for i in testX])\n",
    "\n",
    "        predict[idx] = clf[i].predict(testX)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327437802146\n",
      "0.3757811578823252\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictKNN1.npy')\n",
    "clf = clfKNN1\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        testX = features[i][1].transform([i[0] for i in testX])\n",
    "\n",
    "        predict[idx] = clf[i].predict(testX)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.557363518453\n",
      "0.6587666548756043\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictKNN2.npy')\n",
    "clf = clfKNN2\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        testX = features[i][1].transform([i[0] for i in testX])\n",
    "\n",
    "        predict[idx] = clf[i].predict(testX)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.520575403844\n",
      "0.638486027591086\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictNC.npy')\n",
    "clf = clfNC\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        testX = features[i][1].transform([i[0] for i in testX])\n",
    "\n",
    "        predict[idx] = clf[i].predict(testX)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621388987148\n",
      "0.7224383916990921\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictRC.npy')\n",
    "clf = clfRC\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        testX = features[i][1].transform([i[0] for i in testX])\n",
    "\n",
    "        predict[idx] = clf[i].predict(testX)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573045631411\n",
      "0.6855323664662186\n"
     ]
    }
   ],
   "source": [
    "predict = np.load('data/filterData/multilevel/predictSVC1.npy')\n",
    "clf = clfSVC\n",
    "for i in clf:\n",
    "    idx = np.where(predict == i)[0]\n",
    "    if idx.shape[0] != 0:\n",
    "        testX = testText[idx]\n",
    "        testX = features[i][1].transform([i[0] for i in testX])\n",
    "\n",
    "        predict[idx] = clf[i].predict(testX)\n",
    "\n",
    "sm = 0\n",
    "print(accuracy_score(testCategories, predict))\n",
    "for i in range(len(testCategories)):\n",
    "    if testCategories[i] == predict[i] or \\\n",
    "        parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "        str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "        sm += 1\n",
    "print(sm / len(testCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ansFiles = ['KNN1', 'KNN2', 'RC', 'NC', \"SVC1\"]\n",
    "classifi = [clfKNN1, clfKNN2, clfRC, clfNC, clfSVC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = np.zeros((5, 5, 2))\n",
    "for idx1, str1 in enumerate(ansFiles):\n",
    "    for idx2, clf in enumerate(classifi):\n",
    "        predict = np.load('data/filterData/multilevel/predict' + str1 + '.npy')\n",
    "        \n",
    "        for i in clf:\n",
    "            idx = np.where(predict == i)[0]\n",
    "            if idx.shape[0] != 0:\n",
    "                testX = testText[idx]\n",
    "                testX = features[i][1].transform([i[0] for i in testX])\n",
    "\n",
    "                predict[idx] = clf[i].predict(testX)\n",
    "\n",
    "        sm = 0\n",
    "        ans[idx1][idx2][0] = accuracy_score(testCategories, predict)\n",
    "        for i in range(len(testCategories)):\n",
    "            if testCategories[i] == predict[i] or \\\n",
    "                parents[str(int(testCategories[i]))] == str(int(predict[i])) or\\\n",
    "                str(int(predict[i])) in childrens[str(int(testCategories[i]))]:\n",
    "                sm += 1\n",
    "        ans[idx1][idx2][1] = sm / len(testCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3151751 ,  0.3274378 ,  0.34311992,  0.32000943,  0.3307393 ],\n",
       "       [ 0.53012616,  0.55771725,  0.59509492,  0.5449829 ,  0.55453366],\n",
       "       [ 0.54569037,  0.57611131,  0.62433675,  0.56703219,  0.57870534],\n",
       "       [ 0.49428133,  0.5216366 ,  0.56479189,  0.51680226,  0.53106945],\n",
       "       [ 0.53448886,  0.5638486 ,  0.61148449,  0.55642023,  0.5704516 ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36575875,  0.37554534,  0.38804386,  0.3717722 ,  0.38061549],\n",
       "       [ 0.63730692,  0.66029949,  0.68565028,  0.65746964,  0.66348308],\n",
       "       [ 0.66136069,  0.68671147,  0.72302794,  0.69119208,  0.69626223],\n",
       "       [ 0.59957552,  0.62233227,  0.65428605,  0.6315293 ,  0.63577408],\n",
       "       [ 0.64803679,  0.6725622 ,  0.70793538,  0.67833982,  0.68388162]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd795f62da0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAD8CAYAAAAG730QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6dEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7961bf3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ans[1:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd79657b240>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAD8CAYAAAAG730QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+h+amTCUN/imKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd795db0860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ans[1:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
